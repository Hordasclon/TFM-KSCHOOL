---
title: "TFM_Health_In_Air-DataCleaning"
author: "Marcos Mariscal Garcia"
date: "22/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= "C:/Users/mmariscal/Documents/TFM-KSCHOOL/TFM-KSCHOOL")
knitr::opts_chunk$set(error = FALSE)
```

## Librerias a instalar:
#install.packages("tidyverse") .- tibble using and other tools
#install.packages("sf") .- Geospatial data of several countries
#install.packages("maps") .- USA Regions data 
#install.packages("tools") .- Different R utilites to use in graphic titles for example
#install.packages("utils") .- Severa R utilities
#install.packages("stringr") .- handling of text strings
#install.packages("rnaturalearth") .- Many countries data
#install.packages("rnaturalearthdata").- Needed to create a great map
#install.packages("ggrepel") .- Used for labels do not overlap on the map
#install.packages("magick") .- To generate animations with pre-built maps
#install.packages("readxl") .- for reading excel files
## Calling for the nedeed libraries:

```{r libraries_calls, message=FALSE}
library (yaml)
library(tidyverse)
library(sf) 
library(maps)
library (tools)
library(utils)
library(stringr)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggrepel)
library(transformr)
library(magick)
library(readxl)
library(lubridate)
library(gganimate)

```

---
## Enviroment variables
---

```{r Env_vars, message=FALSE}
#List for the years related to Air Quality Data
datayears = c("2017","2018","2019","2020")
# Defining file names variables to load the data
prename="airdata"
airfilepath="./Data/Air_Quality/"
filename="daily_aqi_by_county_"

if  (!(dir.exists("./png/")))
  {dir.create("./png/")}

pngpath="./png/"
datapath="./Data/"
popfilepath="./Data/Population/"
datapath="./Data/"
```

---------------------------------------------------------------------
## Loading Data from "Dialy Air Quality Monitor"
From: https://www.hcup-us.ahrq.gov/reports/trendtables/summarytrendtables.jsp#export
---------------------------------------------------------------------

```{r AQI_func_load, message=FALSE}
# Reading and group function by year:
getagg <- function(year){

    pathzip <- paste (airfilepath,filename,year,".zip",sep="")
    filecsv <- paste (filename,year,".csv",sep="")

# Loading each csv file:  
    df <- read.table(unz(pathzip, filecsv), header=T, quote="\"", sep=",")
    
# merging year month field to group by it:
    df$yearmm<- paste(substr(df$Date,1,8),"01") 
    df$yearmm<- as.Date(df$yearmm,format="%Y-%m-%d")
    
# Defining numeric values for the AQI categories:      
    df$Cat <- ifelse(df$Category=="Good",1,ifelse(df$Category=="Moderate",2,ifelse(df$Category=="Unhealthy for Sensitive Groups",3,ifelse(df$Category=="Unhealthy",4,ifelse(df$Category=="Very Unhealthy",5,ifelse(df$Category=="Hazardous",5,"Raro"))))))

# Inside function,data group by State:
# AQI index is de maximum index of analyzed componente AQI = max( AQIPM2.5, AQIPM10, AQIO3, ...)
    aggdf <- df %>% select(State.Name, county.Name,Cat,AQI, yearmm) %>% group_by(State.Name, county.Name,yearmm) %>%  summarise(maxCat=max(Cat,na.rm=TRUE),maxAQI=max(AQI,na.rm=TRUE),aggnum=n())

    
  return (aggdf)
}
# End of reading and group by function
```

---
# calling function to load and group Air quality data by 2017 to 2020:
---

```{r AQI_func_call, message=FALSE}

aggtot <- tibble()

# Loop for getting data air quatily
for (i in 1:length(datayears)){
  aggdata <- getagg(datayears[i])
  aggtot <- union_all(aggtot,aggdata)
}

```

----------------------------------------------------------------------------------
## Merging with geographical data for USA Counties, from packages("sf"), and saving as RData:
----------------------------------------------------------------------------------

```{r Usa_Geo_Data, include=FALSE}

#  Generating ID field to join with tibble USA counties:
aggtot$ID <- paste(tolower(aggtot$State.Name),tolower(aggtot$county.Name), sep=",", collapse=NULL)

# Getting geographical data for USA counties:
counties <- st_as_sf(map("county", plot = FALSE, fill = TRUE))
counties$area <- as.numeric(st_area(counties))

# Joining aggregated AQI data with counties geographical data
aggtotcounties <- merge(x = aggtot, y = counties, by = "ID", all.x = TRUE)

# Getting USA states data:
states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))
states$ID <- toTitleCase(states$ID)

#Icluding state area data:
states$area <- as.numeric(st_area(states))

# Getting countries data
world <- ne_countries(scale = "medium", returnclass = "sf")

# Calculate states centroid
states <- cbind(states, st_coordinates(st_centroid(states)))

# Identifying AQI categories:
ncateg<- c(1,2,3,4,5,6)
categ <- c("Good","Moderate","Unhealthy for Sensitive Groups","Unhealthy","Very Unhealthy","Hazardous")

# Defining each AQI category colors
colscateg <- c("1"="green","2"="yellow","3"="orange","4"="red","5"="darkred", "6"="black")

#deleting records with empty areas
no_nulos = aggtotcounties %>% filter(!is.na(area))

Air_Quality_Indexes <-no_nulos

#Convert to numeric
Air_Quality_Indexes$maxCat <- as.numeric(Air_Quality_Indexes$maxCat)
head(Air_Quality_Indexes)

# Saving Tibble with AQI data:
save(Air_Quality_Indexes, file = paste(datapath,"Air_Quality_Indexes.Rdata",sep=""))

#extracting year and month:
dist_yearmm = aggtotcounties %>% distinct(yearmm) %>% arrange(yearmm)

# Getting a list of year month existing in data:
list <- dist_yearmm$yearmm
lista <- as.integer(format(list, "%Y%m%d"))
```

----------------------------------------------------------------------------------
## Now representing Air Quality on a USA geographical detailed by county:
----------------------------------------------------------------------------------

```{r Generate_AQI_png_maps,  include=FALSE,results = FALSE}
#, eval=FALSE
# Generating a map per year and month with air quality data per county

f_maps <- for (i in 1:length(list)){ 
df <- no_nulos  %>% filter(yearmm==list[[i]])
 ggUsa <- ggplot(data = world) +
        geom_sf()+
        geom_sf(data = states) +
        geom_sf(data = df, aes(geometry=geom,fill = maxCat)) +
        scale_fill_manual(values=colscateg, name="AQI Categories",breaks=ncateg, labels=categ) +
        geom_label_repel(size=2,fontface="bold",data = states, aes(x = X, y = Y, label = ID), 
        nudge_x = c(1, -1.5, 2, 2, -1), nudge_y = c(0.25, -0.25, 0.5, 0.5, -0.5)) +
        coord_sf(xlim = c(-130, -58), ylim = c(24.0, 50.1), expand = FALSE) +
        ggtitle(paste("Air Quality in USA Counties",list[i],sep=" "))+
        theme(axis.title.x=element_blank(),axis.title.y=element_blank())
  ggsave(paste(pngpath,"ggUsa",lista[i],".png", sep=""),
         width = 8, height = 6, units = 'in', dpi=110, pointsize=10)
}

```

Now saving maps as .png

```{r AQI_Maps_read, include=FALSE, results = FALSE}
#, eval=FALSE
# Saving generated maps as png images for animating them
imglayers <- sapply(lista, function(ym){
  image_read(paste(pngpath,'ggUsa', ym,'.png',  sep=''))
})
```

Animate maps

```{r AQI_Maps_animate, include=FALSE, results = FALSE}
#, eval=FALSE
# Animating saved maps
imganim <- image_animate(image_join(imglayers),fps=1,dispose="previous")
```

## Including animated GIF of the Air Quality cheks on a USA geographical counties
For the 2017 to 2020 years:

```{r AQI_Maps_show, include=FALSE, results = FALSE}
#, eval=FALSE
image_write(imganim, 'ggUsa.gif')

#giff<-image_read(paste(pngpath,'ggUsa.gif',sep=""))

```

![](C:/Users/mmariscal/Documents/TFM-KSCHOOL/TFM-KSCHOOL/ggUsa.gif)



----------------------------------------------------------------------------------
## Loading New Data Set, Hospital visits related to respiratory diseases:
From: https://www.hcup-us.ahrq.gov/reports/trendtables/summarytrendtables.jsp#export
This is an excel report and the different States date are in different sheets of the same excel workbook
----------------------------------------------------------------------------------
```{r Visits_load, include=FALSE}

Visitspath="./Data/Hospital_Visits/"
Visitsfile="HCUP_SummaryTrendTables_T5a.xlsx"

#List of USA States:
states<- c("Alaska","Arizona","Arkansas","California","Colorado","Connecticut","Delaware","District of Columbia","Georgia","Hawaii","Illinois","Indiana","Iowa","Kansas","Kentucky","Louisiana","Maine","Maryland","Massachusetts","Michigan","Minnesota","Mississippi","Missouri","Montana","Nebraska","Nevada","New Jersey","New Mexico","New York","North Carolina","North Dakota","Ohio","Oklahoma","Oregon","Pennsylvania","Rhode Island","South Carolina","South Dakota","Tennessee","Texas","Utah","Vermont","Virginia","Washington","West Virginia","Wisconsin","Wyoming")


#New column names for the Hospital visits DataSet:
newcols<-c("A_Num_Dis","All_discharges","A_Num_byAge","Ages_0_4","Ages_5_9","Ages_10_17","Ages_18_44","Ages_45_64","Ages_65_79","Ages_80","A_Num_bySex","Male","Female","A_Num_Race","White","Black","Hispanic","All_other_races","Race_not_in_SID","Race_missing","A_Num_Urban_Rural_Res","Resi_L_metro","Resi_M_S_metros","Resi_nonmetro","Resi_missing","A_num_Comm_Income","Quart1_lowest_income","Quart2_3_middle_income","Quart4_highest_income","Missing_income","A_num_exp_payer","Medicare","Medicaid","Private_insurance","Self_pay","Other_pay","Missing_pay","A_num_Hosp_Urb","Hosp_L_metro","Hosp_M_S_metros","Hosp_Nonmetro","Num_Proc_class","Proc_operating_room","Proc_major_therapeutic","Proc_major_diagnostic","A_num_ByType_Intensive","Use_any_intens_care","Use_ICU","Use_CCU","Use_NICU","Use_other_care_units","A_Numb_by_mech_vent","Use_mech_ventilation","A_Num_TopCond","CIR009_myocardial_infar","CIR017_cardiac_dysrhy","CIR019_heart_failur","INF002_septicemia","RSP002_pneumonia","RSP005_acute_bronchitis","RSP008_chronic_pulmonary",
"RSP009_asthma","RSP010_aspiration_pneumonitis","RSP012_respiratory_failure","All_other_conditions")


#New tibble to contain all Hospital visits data
dftotvisits <- tibble()

#We go through all the USA states with a loop, reading all excel sheets, except Alaska
for (i in 2:length(states)){

  #reading each excel sheets and the range from cell A7 to cell AW72:
  dfvisits <-read_excel(paste(Visitspath,Visitsfile,sep=""), 
                          sheet=states[i],range ="A7:AW72") 

  dfvisits<-add_column(dfvisits, new_cols=newcols,.before='Characteristic by Month')

  #Borramos la columna anterior de descripciones original:
  dfvisits <- select(dfvisits,-c('Characteristic by Month'))

# Pivoting longer the dates columns to row forcing the result to character type:
dfwide <- dfvisits %>% tidyr::pivot_longer(.,-c('new_cols') ,names_to="Dates",values_to="result",values_transform = list(result = as.character))

# Erasing rows with no value:
dfwide <- dfwide %>% drop_na(result)

# transforms numeric dates of excel format to tibble date type:
dfwide$Dates <- as.numeric(dfwide$Dates)-2

dfwide$Dates <- as.Date(dfwide$Dates, origin = "1900-01-01")

#Pivoting quantitive values from files to columns
dflong <- dfwide %>% tidyr::pivot_wider(names_from ='new_cols',values_from= "result")

#eliminamos los valores "***" para poder convertir las columnas a numéricas:
dflong <- dflong %>% mutate(across(where(is.character), ~na_if(., "***")))

dflong <- dflong %>% mutate(across(where(is.character), as.integer))

#Incluimos el valor del nombre de estado en todas las filas ya formateadas
dflong<-add_column(dflong, ID=states[i],.after='Dates')

dftotvisits <- union_all(dftotvisits,dflong)
}
#Se cierra el bucle de lectura de todas las hojas excel

#Media Desviación standard y tasa media de las visitas hospitalarias por año (Year=as.integer(format(Dates, "%Y")) y estado:
medsd_visits <- dftotvisits %>% group_by(ID) %>% summarize(average = mean(All_discharges), standard_deviation = sd(All_discharges), median_rate=median(All_discharges))

```

----------------------------------------------------------------------------------
## Including geographical USA states data to attach to the Hospital visits dataset
----------------------------------------------------------------------------------

```{r Visits_states, include=FALSE}

#Idenfying Hospital visits urgency types
nvisits<- c(1,2,3,4,5,6)
catvisits<- c("Good","Moderate","Unhealthy for Sensitive Groups","Unhealthy","Very Unhealthy","Hazardous")

#Defining colors for each category value
colsvisits <- c("1"="green","2"="yellow","3"="orange","4"="red","5"="darkred", "6"="black")


#Getting USA States data from sf library

states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))

states$ID <- toTitleCase(states$ID)

#Including area data of USA States in "state" dataframe
states$area <- as.numeric(st_area(states))

world <- ne_countries(scale = "medium", returnclass = "sf")

states <- cbind(states, st_coordinates(st_centroid(states)))

# Merging Hospital Visits with geographical data by USA States

 Hospital_Visits_by_State <- merge(x = dftotvisits, y = states, by = "ID", all.x = TRUE) 

```

---
# Generating a map with Hospital Visists per year and month
---

```{r Visits_map, echo=FALSE,include=FALSE}
##, eval=FALSE

#utils::View(Hospital_Visits_by_State)# for watching all dataframe, normal view function just show first 50 columns

#Getting different dates to include in a list:
dist_dates = Hospital_Visits_by_State %>% distinct(Dates) %>% arrange(Dates)
dates = dist_dates$Dates

f_visits_maps <- for (i in 1:length(dates)){ 
df <- Hospital_Visits_by_State  %>% filter(Dates==dates[i])

 ggUsa <- ggplot(data = world) +
        geom_sf()+
        geom_sf(data = states) +
        geom_sf(data = df, aes(geometry=geom,fill = All_discharges)) +
        geom_label_repel(size=2,fontface="bold",data = states, aes(x = X, y = Y, label = ID), 
        nudge_x = c(1, -1.5, 2, 2, -1), nudge_y = c(0.25, -0.25, 0.5, 0.5, -0.5)) +
        coord_sf(xlim = c(-130, -58), ylim = c(24.0, 50.1), expand = FALSE) +
        ggtitle(paste("Hospital Visits in USA States",dist_dates$Dates[i],sep=" "))+
        theme(axis.title.x=element_blank(),axis.title.y=element_blank())

# Saving all generated maps as images (.png):
  ggsave(paste(pngpath,"ggVisitsUsa",dates[i],".png", sep=""),
         width = 8, height = 6, units = 'in', dpi=110, pointsize=10)
  
}
```

# Looping all created maps for a moving image

```{r looping_maps, echo=FALSE}

imgvislayers <- sapply(dates, function(jm){
  image_read(paste(pngpath,'ggVisitsUsa', jm,'.png',  sep=''))
  })

```

---
## Saving generated maps
---

```{r save_visits_map, echo=FALSE}
## , eval=FALSE

# Generating a moving image from saved maps
imganimvisits <- image_animate(image_join(imgvislayers),fps=1,dispose="previous")

```

---
## Generating an animated map of Hospital Visists
---


```{r showing_visits_map, echo=FALSE}
gif_file="ggvisitsUsa.gif"

image_write(imganimvisits,gif_file)

#giffvisits<-image_read(,gif_file,sep="")
```

![](C:/Users/mmariscal/Documents/TFM-KSCHOOL/TFM-KSCHOOL/ggvisitsUsa.gif)

---
## Loading population data from 2017 to 2020 by State
From: https://www2.census.gov/programs-surveys/popest/datasets/2010-2020/state/totals/USA
---

```{r PopulationData_load, echo=FALSE}
# Defining file names variables to load the data
popfilepath="./Data/Population/"
filename="nst-est2020-alldata.csv"
pngpath="./png/"
datapath="./Data/"

#Loading csv data for USA population by State and per year, since 2017 to 2020

    df_pop <- read.table( paste(popfilepath,filename,sep=""), header=T, quote="\"", sep=",")

#Getting only data from 2017 to 2020    
    
    df_pop <- df_pop%>%select (REGION, DIVISION, STATE, NAME, POPESTIMATE2017,POPESTIMATE2018,POPESTIMATE2019,POPESTIMATE2020)

#Pivoting columns with data in different years to files
    
df_pop_wide <- df_pop %>% tidyr::pivot_longer(c('POPESTIMATE2017','POPESTIMATE2018','POPESTIMATE2019','POPESTIMATE2020') ,names_to="EST",values_to="POPULATION")

#Extract Year from EST field
df_pop_wide$YEAR <- substr(df_pop_wide$EST,12,15)

# Transform YEAR field to numeric type
df_pop_wide$YEAR <- as.numeric(df_pop_wide$YEAR)

df_pop_wide <- df_pop_wide%>%select (-EST)


###df_pop_wide$NAMYEAR <- paste(df_pop_wide$NAME,df_pop_wide$YEAR)

head(df_pop_wide)

#Getting distinct States and monthly dates from Hospital Visits
States_dates = Hospital_Visits_by_State %>% distinct(ID,Dates) %>% arrange(ID,Dates)

#Rename the column ID to NAME
names(States_dates)[names(States_dates) == "ID"] <- "NAME"

#Extract Year from Date field
States_dates$YEAR <- year(States_dates$Dates)

#Merging Yearly Population by state with all month data also by state, having duplicated values each month of one year

df_pop_dates<- left_join(x = States_dates,y = df_pop_wide, by=c("NAME","YEAR"), all.x = TRUE)

#Rename the column ID NAME to STATE
names(df_pop_dates)[names(df_pop_dates) == "NAME"] <- "STATES"
#Rename the column ID to STATE
names(Hospital_Visits_by_State)[names(Hospital_Visits_by_State) == "ID"] <- "STATES"

# Merging Population by state with Hospital visits data
Hosp_visits_pop_by_state <- left_join(x = Hospital_Visits_by_State, y = df_pop_dates, by=c("STATES","Dates"),all.x = TRUE)

utils::View(Hosp_visits_pop_by_state)

# Saving in a data file the Tibble with Hospital data Visits and States population:

save(Hosp_visits_pop_by_state, file = paste(datapath,"Hosp_visits_pop_by_state.Rdata",sep=""))


```
